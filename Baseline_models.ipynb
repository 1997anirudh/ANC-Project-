{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RkcRnVIXkH1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smHJXOQ9Xo3v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWb9XjzJX5N5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/US_Accidents_Dec20_updated.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57YckfL3X8xM"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k01SUYvDYkg9"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knb_6BYJYrfA"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpiHS0W7Y083"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6Qb5Zw3ZFwA"
      },
      "outputs": [],
      "source": [
        "df.Severity.value_counts(normalize=True).sort_index().plot.bar()\n",
        "plt.grid()\n",
        "plt.title('Severity')\n",
        "plt.xlabel('Severity')\n",
        "plt.ylabel('Fraction');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcSTIMz6ZZri"
      },
      "outputs": [],
      "source": [
        "bool_cols = [col for col in df.columns if df[col].dtype ==np.dtype('bool')]\n",
        "booldf = df[bool_cols]\n",
        "not_one_hot = booldf[booldf.sum(axis=1) > 1]\n",
        "print('There are {} non one hot metadata rows, which are {:.1f}% of the data'.format(len(not_one_hot),100*len(not_one_hot)/len(df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPcOFXQUZgS6"
      },
      "outputs": [],
      "source": [
        "bools = booldf.sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hCmMjaSZg4-"
      },
      "outputs": [],
      "source": [
        "bools.plot.pie(figsize=(13,13))\n",
        "plt.ylabel('')\n",
        "plt.title('Proximity to Traffic Object');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzx6qPEOZlvv"
      },
      "outputs": [],
      "source": [
        "st = pd.to_datetime(df.Start_Time, format='%Y-%m-%d %H:%M:%S')\n",
        "end = pd.to_datetime(df.End_Time, format='%Y-%m-%d %H:%M:%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YU_FBHCZpFf"
      },
      "outputs": [],
      "source": [
        "diff = (end-st)\n",
        "top20 = diff.astype('timedelta64[m]').value_counts().nlargest(20)\n",
        "print('top 20 accident durations correspond to {:.1f}% of the data'.format(top20.sum()*100/len(diff)))\n",
        "(top20/top20.sum()).plot.bar(figsize=(14,14))\n",
        "plt.title('Accident Duration [Minutes]')\n",
        "plt.xlabel('Duration [minutes]')\n",
        "plt.ylabel('Fraction');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtXmwkqjZugS"
      },
      "outputs": [],
      "source": [
        "df['time'] = pd.to_datetime(df.Start_Time, format='%Y-%m-%d %H:%M:%S')\n",
        "df = df.set_index('time')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34-ebzTJZx2p"
      },
      "outputs": [],
      "source": [
        "freq_text = {'D':'Daily','W':'Weekly','Y':'Yearly'}\n",
        "plt.subplots(1,3,figsize=(21,7))\n",
        "for i, (fr,text) in enumerate(freq_text.items(),1):\n",
        "    plt.subplot(1,3,i)\n",
        "    sample = df.ID['2016':].resample(fr).count()\n",
        "    sample.plot(style='.')\n",
        "    plt.title('Accidents, {} count'.format(text))\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Accident Count');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DhaaLriZ0jq"
      },
      "outputs": [],
      "source": [
        "years = ['2016','2017','2018']\n",
        "fig, _ = plt.subplots(1,3,figsize=(21,7), sharex='all', sharey='all')\n",
        "\n",
        "fig.suptitle('Accidents by month for Different Years')\n",
        "plt.xlabel('month')\n",
        "plt.ylabel('Accidents')\n",
        "for i, year in enumerate(years,1):\n",
        "    plt.subplot(1,3,i)\n",
        "    sample = df.loc[year].ID.resample('M').count()\n",
        "    sample.plot()\n",
        "    plt.ylim(0,100000)\n",
        "    plt.title('Accidents, {} count'.format(text))\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Accident Count');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrZV7vusZ3wU"
      },
      "outputs": [],
      "source": [
        "df['Weekday'] = df.index.day_name()\n",
        "weekday = df.groupby('Weekday').ID.count()\n",
        "weekday = weekday/weekday.sum()\n",
        "dayOfWeek=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "weekday[dayOfWeek].plot.bar()\n",
        "plt.title('Accidents by Weekday')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Accidents');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grqg9zH4Z6yn"
      },
      "outputs": [],
      "source": [
        "years = ['2016','2017','2018']\n",
        "fig, _ = plt.subplots(1,3,figsize=(21,7), sharex='all', sharey='all')\n",
        "\n",
        "fig.suptitle('Accidents by Weekday for Different Years')\n",
        "plt.xlabel('Weekday')\n",
        "plt.ylabel('Accidents')\n",
        "for i, year in enumerate(years,1):\n",
        "    weekday = df.loc[year].groupby('Weekday').ID.count()\n",
        "    weekday = weekday/weekday.sum()\n",
        "    dayOfWeek=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
        "    plt.subplot(1,3,i)\n",
        "    plt.title(year)\n",
        "    weekday[dayOfWeek].plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyAefGB-aDwZ"
      },
      "outputs": [],
      "source": [
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title('Correlation Matrix, fontsize=15')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_IrqB1chjtm"
      },
      "outputs": [],
      "source": [
        "df.groupby('State') \\\n",
        "        .size() \\\n",
        "        .iloc[:10] \\\n",
        "        .sort_values(ascending=False) \\\n",
        "        .plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDijW7SgaMyn"
      },
      "outputs": [],
      "source": [
        "df1 = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pILyby0sdO1i"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvjUFE15juWZ"
      },
      "outputs": [],
      "source": [
        "df1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk83i5QcaWIQ"
      },
      "outputs": [],
      "source": [
        "df1 = df1.drop(['Distance(mi)', 'Country', 'Description', 'City', 'County', 'Street', 'Side', 'Zipcode', 'State', 'Airport_Code', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gZbzXWiawYj"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiYb8_ofaSCu"
      },
      "outputs": [],
      "source": [
        "cols = [\"End_Lat\", \"End_Lng\", \"Number\"]\n",
        "df1 = df1.drop(cols, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHzfonACaUD9"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mXUAoJLaY74"
      },
      "outputs": [],
      "source": [
        "pmean = df1['Pressure(in)'].mean()\n",
        "tmean = df1['Temperature(F)'].mean()\n",
        "wcmean = df1['Wind_Chill(F)'].mean()\n",
        "hmean = df1['Humidity(%)'].mean()\n",
        "wsmean = df1['Wind_Speed(mph)'].mean()\n",
        "prmean = df1['Precipitation(in)'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23IqeHtw_mbW"
      },
      "outputs": [],
      "source": [
        "df1['Pressure(in)']=df1['Pressure(in)'].fillna(pmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lNEUP2f_3tW"
      },
      "outputs": [],
      "source": [
        "df1['Temperature(F)'] = df1['Temperature(F)'].fillna(tmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay9E2rdZ_63c"
      },
      "outputs": [],
      "source": [
        "df1['Wind_Chill(F)'] = df1['Wind_Chill(F)'].fillna(wcmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh6M8cNC_7Ot"
      },
      "outputs": [],
      "source": [
        "df1['Humidity(%)'] = df1['Humidity(%)'].fillna(hmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNoZgpj0Aaz2"
      },
      "outputs": [],
      "source": [
        "df1['Wind_Speed(mph)'] = df1['Wind_Speed(mph)'].fillna(wsmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqMLI_93Abry"
      },
      "outputs": [],
      "source": [
        "df1['Precipitation(in)']=df1['Precipitation(in)'].fillna(prmean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt4Jp35NaPr_"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD8olrW3ohcm"
      },
      "outputs": [],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnqBDo-Xabq5"
      },
      "outputs": [],
      "source": [
        "visMode = df1[\"Visibility(mi)\"].mode()\n",
        "#df1[\"Visibility(mi)\"]=df1[\"Visibility(mi)\"].fillna(visMode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SovJKB6aRv3q"
      },
      "outputs": [],
      "source": [
        "#df1[\"Visibility(mi)\"]=df1[\"Visibility(mi)\"].fillna(visMode)\n",
        "df1['Visibility(mi)'] = df1['Visibility(mi)'].fillna(df1['Visibility(mi)'].mode()[0])\n",
        "df1['Wind_Direction'] = df1['Wind_Direction'].fillna(df1['Wind_Direction'].mode()[0])\n",
        "df1['Weather_Condition'] = df1['Weather_Condition'].fillna(df1['Weather_Condition'].mode()[0])\n",
        "df1['Sunrise_Sunset'] = df1['Sunrise_Sunset'].fillna(df1['Sunrise_Sunset'].mode()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8_RylJsRv3s"
      },
      "outputs": [],
      "source": [
        "df1.drop(['Timezone','Weather_Timestamp', 'Start_Time', 'End_Time', 'ID'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKeYpHHgVjxs"
      },
      "outputs": [],
      "source": [
        "df1.dropna(axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwVVMjyWCTX2"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6y9KNd-Rv3w"
      },
      "outputs": [],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKeAhTyrCV3j"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df1['Amenity'] = label_encoder.fit_transform(df1['Amenity'])\n",
        "df1['Bump'] = label_encoder.fit_transform(df1['Bump'])\n",
        "df1['Crossing'] = label_encoder.fit_transform(df1['Crossing'])\n",
        "df1['Give_Way'] = label_encoder.fit_transform(df1['Give_Way'])\n",
        "df1['Junction'] = label_encoder.fit_transform(df1['Junction'])\n",
        "df1['No_Exit'] = label_encoder.fit_transform(df1['No_Exit'])\n",
        "df1['Railway'] = label_encoder.fit_transform(df1['Railway'])\n",
        "df1['Roundabout'] = label_encoder.fit_transform(df1['Roundabout'])\n",
        "df1['Station'] = label_encoder.fit_transform(df1['Station'])\n",
        "df1['Stop'] = label_encoder.fit_transform(df1['Stop'])\n",
        "df1['Traffic_Calming'] = label_encoder.fit_transform(df1['Traffic_Calming'])\n",
        "df1['Traffic_Signal'] = label_encoder.fit_transform(df1['Traffic_Signal'])\n",
        "df1['Turning_Loop'] = label_encoder.fit_transform(df1['Turning_Loop'])\n",
        "df1.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlUpAk7eRv33"
      },
      "outputs": [],
      "source": [
        "df1['Sunrise_Sunset'] = label_encoder.fit_transform(df1['Sunrise_Sunset'])\n",
        "df1['Weather_Condition'] = label_encoder.fit_transform(df1['Weather_Condition'])\n",
        "df1['Wind_Direction'] = label_encoder.fit_transform(df1['Wind_Direction'])\n",
        "df1['Weekday'] = label_encoder.fit_transform(df1['Weekday'])\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4tjGrSNRv4G"
      },
      "outputs": [],
      "source": [
        "Y = df1['Severity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG4Dn3G9Rv4K"
      },
      "outputs": [],
      "source": [
        "X = df1.drop(['Severity'], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIUvfAGjRv4N"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CJbzNxNRv4Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(.95)\n",
        "pca.fit(X)\n",
        "train_img = pca.transform(X)\n",
        "train = pd.DataFrame(train_img)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CONdYuRRv4V"
      },
      "outputs": [],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting the dataset into train and test, where 80% is used to train the model and 20% of the dataset is used to test. "
      ],
      "metadata": {
        "id": "gswG3X5ZPzoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxWKP4zMRv4c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### StandardScaler removes the mean and scales each feature/variable to unit variance."
      ],
      "metadata": {
        "id": "WUYQV44WQcFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CJZjda_Rv4f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Fit on training set only.\n",
        "scaler.fit(X_train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "transform = scaler.transform(X_train)\n",
        "scalar_train = pd.DataFrame(transform)\n",
        "scalar_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIj4MQXYhiw0"
      },
      "outputs": [],
      "source": [
        "scalert = StandardScaler()\n",
        "# Fit on training set only.\n",
        "scalert.fit(X_test)\n",
        "# Apply transform to both the training set and the test set.\n",
        "transformt = scalert.transform(X_test)\n",
        "#test_img = scaler.transform(test_img)\n",
        "scalar_test = pd.DataFrame(transformt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MLP Classifier, modifying hyperparameters to achieve good accuracy"
      ],
      "metadata": {
        "id": "yIXhKLj_RhQ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT5dEa1scZnt"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf_MLP = MLPClassifier(solver='adam', alpha=0.0001,\n",
        "                    hidden_layer_sizes=(10, 10), random_state=1,max_iter=100,learning_rate_init=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzeCjc9XgJ6z"
      },
      "outputs": [],
      "source": [
        "clf_MLP.fit(scalar_train, y_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQkxTZhOhlm4"
      },
      "outputs": [],
      "source": [
        "y_pred=clf_MLP.predict(scalar_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSuXpgHahvA6"
      },
      "outputs": [],
      "source": [
        "clf_MLP.score(scalar_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQF7Y9FBlg4H"
      },
      "outputs": [],
      "source": [
        "clf_MLP1 = MLPClassifier(solver='adam', alpha=0.0001,\n",
        "                    hidden_layer_sizes=(20, 20, 20), random_state=1,max_iter=100,learning_rate_init=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtIiMTtGvAvy"
      },
      "outputs": [],
      "source": [
        "clf_MLP1.fit(scalar_train, y_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsY-E7HfvFvj"
      },
      "outputs": [],
      "source": [
        "clf_MLP1.score(scalar_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression, modifying hyperparameters to achieve good accuracy "
      ],
      "metadata": {
        "id": "kUp_3y1PSlEB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "933HeZy1lNSh"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lore =LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ0NMjTsy1hO"
      },
      "outputs": [],
      "source": [
        "y_pred_lore = lore.predict(scalar_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwM40s8GnfjM"
      },
      "outputs": [],
      "source": [
        "lore.score(scalar_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPUwUdnDnrbI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred_lore)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DecisionTreeClassifier, modifying hyperparameters to achieve good accuracy"
      ],
      "metadata": {
        "id": "eHM-HTtzS_uc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoOwuAmImvhT"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "d_tree = DecisionTreeClassifier(random_state = 42, max_depth=2,min_samples_leaf = 2,criterion = \"entropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auMxo2V5m6GD"
      },
      "outputs": [],
      "source": [
        "d_tree = d_tree.fit(scalar_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyGfz35qm8lq"
      },
      "outputs": [],
      "source": [
        "y_pred_d_tree = d_tree.predict(scalar_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XT2P2zwnAO8"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_d_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RandomForestClassifier, modifying hyperparameters to achieve good accuracy."
      ],
      "metadata": {
        "id": "r52lKrjtTI0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj1ZQU2KzkM0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rafo=RandomForestClassifier(n_estimators=100,min_samples_leaf = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa6LuUbAzvwR"
      },
      "outputs": [],
      "source": [
        "rafo.fit(scalar_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-rNUi7azzZ2"
      },
      "outputs": [],
      "source": [
        "y_pred_rafo=rafo.predict(scalar_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOCcI37Zz3Cs"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rafo))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KNN Model, modifying hyperparameters to achieve good accuracy. "
      ],
      "metadata": {
        "id": "tBIjJbFBTkLh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD6yQW8G0hzy"
      },
      "outputs": [],
      "source": [
        "# K nearest neighbour classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=10)\n",
        "neigh.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCApnQPn1FPe"
      },
      "outputs": [],
      "source": [
        "# Accuracy metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = neigh.predict(X_test)\n",
        "accuracy= accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Baseline_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}